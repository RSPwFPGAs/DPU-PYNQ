{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import poly_yolo as yolo #or \"import poly_yolo_lite as yolo\" for the lite version\n",
    "#import poly_yolo_lite as yolo\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import keras\n",
    "from keras.models import model_from_json, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set the learning phase to Test since the model is already trained.\n",
    "keras.backend.set_learning_phase(0)\n",
    "\n",
    "#load pretrained model\n",
    "#if you want to detect more objects, lower the score and vice versa\n",
    "trained_model = yolo.YOLO(model_path='models/poly_yolo.h5', iou=0.5, score=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trained_model.yolo_model.layers[0].input)\n",
    "print(trained_model.yolo_model.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save checkpoint\n",
    "saver = tf.train.Saver()\n",
    "tf_session = keras.backend.get_session()\n",
    "input_graph_def = tf_session.graph.as_graph_def()\n",
    "save_path = saver.save(tf_session, './checkpoint.ckpt')\n",
    "tf.train.write_graph(input_graph_def,\n",
    "                     './', 'poly_yolo_dpu.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the node names \n",
    "nodes_names = [node.name for node in \n",
    "               tf.get_default_graph().as_graph_def().node]\n",
    "print(nodes_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!freeze_graph --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Freeze Tensorflow graph: lastnode: concat_9; lastlayer: conv2d_69/BiasAdd\n",
    "!freeze_graph \\\n",
    "    --input_meta_graph checkpoint.ckpt.meta \\\n",
    "    --input_checkpoint checkpoint.ckpt \\\n",
    "    --output_graph frozen.pb \\\n",
    "    --output_node_names conv2d_69/BiasAdd \\\n",
    "    --input_binary true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#confirm available input and output node names\n",
    "!vai_q_tensorflow inspect --input_frozen_graph=frozen.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Prepare calibration data and function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "dir_imgs_name = '../cityscapes/leftImg8bit_demoVideo/leftImg8bit/demoVideo/stuttgart_01/'  #path_where_are_images_to_clasification\n",
    "list_of_imgs = [root+\"/\"+name for root, dirs, files in os.walk(dir_imgs_name) for name in files]    \n",
    "list_of_imgs.sort()\n",
    "num_imgs = 32\n",
    "\n",
    "# get the 1st image with right shape\n",
    "img = load_img(list_of_imgs[0])  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (1024, 2048, 3)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 1024, 2048, 3)\n",
    "dataset_calib = x\n",
    "# fill in the following images\n",
    "imgs          = 0\n",
    "for im in range (1, num_imgs):#len(list_of_imgs)):\n",
    "    imgs    += 1\n",
    "    img = load_img(list_of_imgs[im])  # this is a PIL image\n",
    "    x = img_to_array(img)  # this is a Numpy array with shape (1024, 2048, 3)\n",
    "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 1024, 2048, 3)\n",
    "    dataset_calib = np.append(dataset_calib, x, axis=0)\n",
    "print('Calibration data: {}, {}, {}'.format(dataset_calib.shape, dataset_calib.ndim, dataset_calib.dtype))\n",
    "\n",
    "np.savez('./calib_data.npz', data = dataset_calib[:num_imgs])\n",
    "\n",
    "del(dataset_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile input_func.py\n",
    "import numpy as np\n",
    "\n",
    "data = np.load('calib_data.npz')['data']\n",
    "\n",
    "batch_size=1\n",
    "\n",
    "def calib_input(iter):\n",
    "\n",
    "    calib_data = data[iter*batch_size:(iter+1)*batch_size]\n",
    "\n",
    "    return {'input_1': calib_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!vai_q_tensorflow quantize --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!vai_q_tensorflow quantize \\\n",
    "    --input_frozen_graph frozen.pb \\\n",
    "    --input_fn input_func.calib_input \\\n",
    "    --output_dir quantized \\\n",
    "    --input_nodes input_1 \\\n",
    "    --output_nodes conv2d_69/BiasAdd \\\n",
    "    --input_shapes ?,1024,2048,3 \\\n",
    "    --skip_check 0 \\\n",
    "    --simulate_dpu 1 \\\n",
    "    --calib_iter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vai_c_tensorflow \\\n",
    "    --frozen_pb quantized/deploy_model.pb \\\n",
    "    --arch ../../Ultra96.json \\\n",
    "    --output_dir . \\\n",
    "    --net_name poly_yolo_dpu_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "yolo-v4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
